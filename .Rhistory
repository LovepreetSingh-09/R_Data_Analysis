view(airports)
flights2 %>% left_join(airports,by=c('origin'='faa'))
airports %>%
semi_join(flights, c("faa" = "dest")) %>%
ggplot(aes(lon, lat)) +
borders("state") +geom_point() +
coord_quickmap()
top_dest <- flights %>%
count(dest, sort = TRUE) %>%
head(10)
top_dest
flights %>% filter(dest %in% top_dest$dest)
# This can be easily done by semi_join which represent the intersect or common values
semi_join(flights,top_dest)
# anti_join represent the values ehich are only in the left dataset not in the 2nd one.
anti_join(flights,planes,by='tailnum') %>%
count(tailnum,sort=T)
# set operations :-
# intersect for common values
# union for both the values
# setdiff for values in x not in y
df1 <- tribble(
~x, ~y,
1, 1,
2, 1
)
df2 <- tribble(
~x, ~y,
1, 1,
1, 2
)
intersect(df1, df2)
union(df1,df2)
setdiff(df1,df2)
setdiff(df2.df1)
setdiff(df2,df1)
library(tidyverse)
library(nycflights13)
str_length(c("a", "R for data science", NA))
# combine strings
str_c(c("x","y"))
# combine strings
str_c("x","y")
str_c("x","y","z",sep=',')
str_c('|-',x,'-|')
x=c("abc",NA)
str_c('|-',x,'-|')
str_c("|-",str_replace_na(x),"-|")
str_c("prefix-", c("a", "b", "c"), "-suffix")
str_c(c("x", "y", "z"), collapse = ", ")
str_sub(x,1,4)
# sunbsetting strings
x <- c("Apple", "Banana", "Pear")
str_sub(x,1,4)
str_sub(x,-3,-1)
str_sub(x,1,1)=str_to_lower(str_sub(x,1,1))
x
# Locales
str_to_upper(c("i", "ı"))
str_to_upper(c("i", "ı"),locale='tr')
str_sort(x,locale='hi')
str_sort(x,locale='pun')
str_sort(x,locale='haw')
str_sort(x, locale = "en")
str_sort(x,locale='haw')
x <- c("apple", "eggplant", "banana")
str_sort(x, locale = "en")
str_sort(x,locale='haw')
str_sort(x,locale='pun')
source('~/R/R_Data_Analysis/stringr.R', encoding = 'UTF-8')
str_view(x,'a,')
str_view(x,'a.')
str_view(x,'.a.')
install.packages("htmlwidgets")
install.packages("htmlwidgets")
library(htmlwidgets)
str_view(x,'.a.')
# To create the regular expression, we need \\
dot <- "\\."
# But the expression itself only contains one:
writeLines(dot)
# And this tells R to look for an explicit .
str_view(c("abc", "a.c", "bef"), "a\\.c")
x='a\\b'
str_view(x,'\\\\')
x <- c("apple", "banana", "pear")
str_view(x, "^a")
str_view(x,'a$')
str_view(x, "apple4")
str_view(x, "apple$")
x <- c("apple pie", "apple", "apple cake")
str_view(x, "apple$")
str_view(c("grey", "gray"),'gr(e|a)y')
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")
str_view(x,'CC+')
str_view(x,'C[LX]+')
str_view(x,'C{2}')
str_view(x,'C{3}')
str_view(x,'C{2,3}')
# RegExp shows greedy behaviour means takes the longest streak of match
# To find the short match we can use ? after the expression
str_view(x,'C[LX]+?')
str_view(fruit, "(..)\\1", match = TRUE)
str_view(fruit, "(..)\\2", match = TRUE)
#
fruits
#
fruit
x<- c("apple", "banana", "pear")
str_detect(x, "e")
str_match(fruit,'(..)\\1')
str_match_all(fruit,'(..)\\1')
str_match(fruit,'(..)\\1')
sum(str_detect(words,'^t'))
words
mean(str_detect(words,'[aeiou]$'))
no_vowels_1 <- !str_detect(words, "[aeiou]")
no_vowels_2 <- str_detect(words,'^[^aeiou]$')
identical(n0_vowels1==no_vowels_2)
identical(no_vowels1==no_vowels_2)
no_vowels_1 <- !str_detect(words, "[aeiou]")
no_vowels_2 <- str_detect(words,'^[^aeiou]$')
identical(no_vowels1==no_vowels_2)
identical(no_vowels_1==no_vowels_2)
identical(no_vowels_1,no_vowels_2)
no_vowels_1 <- !str_detect(words, "[aeiou]")
no_vowels_2 <- str_detect(words,'^[^aeiou]$')
identical(no_vowels_1,no_vowels_2)
no_vowels_2 <- str_detect(words,'^[^aeiou]+$')
identical(no_vowels_1,no_vowels_2)
words[str_detect(words,'x$')]
# This is same as
str_sub(words,'x$')
# This is same as
str_subset(words,'x$')
df <- tibble(
word = words,
i = seq_along(word))
df
df %>% str_detect(word,'x$')
df %>% filter(str_detect(word,'x$'))
str_count(x,'a')
mean(str_count(words, "[aeiou]"))
df %>% mutate(vowels=str_count(word,'[aeiou]'),
consonants=str_count(word,'[^aeiou]'))
str_count("abababa", "aba")
str_view('abababa','aba')
str_view_all('abababa','aba')
length(sentences)
head(sentences)
colors <- c(
"red", "orange", "yellow", "green", "blue", "purple")
color_match <- str_c(colors, collapse = "|")
color_match
str_subset(sentences,colour_match)
str_subset(sentences,color_match)
subset <- str_subset(sentences,color_match)
str_extract(subset,color_match)
more <- sentences[str_count(sentences, color_match) > 1]
more
str_count(sentences, color_match) > 1
str_count("abababa", "aba")
str_count(sentences, color_match)
more
str_extract(more,color_match)
str_extract_all(more,color_match)
str_extract_all(more,color_match,simplify = T)
str_extract_all(more,color_match,simplify = TRUE)
x <- c("a", "a b", "a b c")
str_extract_all(x, "[a-z]", simplify = TRUE)
noun='(the|a) ([^ ]+)'
has_noun <- sentences %>%
str_subset(noun) %>%
head(10)
has_noun
has_noun %>% str_extract_all(noun)
has_noun %>% str_extract(noun)
has_noun %>% str_extract_all(noun,simplify=TRUE)
has_noun %>% str_extract(noun,simplify=TRUE)
has_noun %>% str_extract(noun)
has_noun %>% str_match(noun)
tibble(sentence=sentences) %>%
tidyr::extract(sentence,c('article','noun'),'noun')
tibble(sentence=sentences) %>%
tidyr::extract(sentence,c('article','noun'),noun)
tibble(sentence=sentences) %>%
tidyr::extract(sentence,c('article','noun'),noun,remove=FALSE)
str_replace(x,'[aeiou]','-')
str_replace_all(x,'[aeiou]','-')
str_replace(x,'[aeiou]','-')
str_replace(x, "[aeiou]", "-")
x <- c("apple", "pear", "banana")
str_replace(x,'[aeiou]','-')
str_replace_all(x,'[aeiou]','-')
x <- c("1 house", "2 cars", "3 people")
str_replace_all(x,c('1'='one','2'='two','3'='three'))
sentences %>% head(5)
sentences %>%
str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>%
head(5)
# flipping the 3rd and 2nd word of string
sentences %>%
str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>%
head(5)
sentences %>%
head(5) %>%
str_split(" ")
"a|b|c|d" %>%
str_split('\\|')
"a|b|c|d" %>%
str_split('\\|') %>% .[1]
"a|b|c|d" %>%
str_split('\\|') %>% .[[1]]
"a|b|c|d" %>%
str_split('\\|') %>% [[1]] # .
sentences %>%
head(5) %>%
str_split(" ", simplify = TRUE)
fields %>% str_split(": ", n = 3, simplify = TRUE)
fields %>% str_split(": ", n = 2, simplify = TRUE)
fields <- c("Name: Hadley", "Country: NZ", "Age: 35")
fields %>% str_split(": ", n = 3, simplify = TRUE)
fields %>% str_split(": ", n = 1, simplify = TRUE)
fields %>% str_split(": ", n = 4, simplify = TRUE)
fields %>% str_split(": ", n = 2, simplify = TRUE)
x <- "This is a sentence. This is another sentence."
str_view_all(x, boundary("word"))
str_view(x, boundary("word"))
str_split(x, boundary("word"))[[1]]
str_view(fruit, regex("nana"))
# multiline = TRUE allows ^ and $ to match the start and end of
# each line rather than the start and end of the complete string
x <- "Line 1\nLine 2\nLine 3"
str_extract_all(x, "^Line")[[1]]
str_extract_all(x, "^Line")
str_extract_all(x, regex("^Line", multiline = TRUE))[[1]]
phone <- regex("
\\(? # optional opening parens
(\\d{3}) # area code
[)- ]? # optional closing parens, dash, or space
(\\d{3}) # another three numbers
[ -]? # optional space or dash
(\\d{3}) # three more numbers
", comments = TRUE)
str_match("514-791-8141", phone)
# fixed() matches exactly the specified sequence of bytes. It ignores all special regular expressions
# and operates at a very low level. This allows you to avoid complex escaping and can be
# much faster than regular expressions.
microbenchmark::microbenchmark(
fixed = str_detect(sentences, fixed("the")),
regex = str_detect(sentences, "the"),
times = 20)
install.packages("microbenchmark")
a1 <- "\u00e1"
a2 <- "a\u0301"
library(microbenchmark)
# fixed() matches exactly the specified sequence of bytes. It ignores all special regular expressions
# and operates at a very low level. This allows you to avoid complex escaping and can be
# much faster than regular expressions.
microbenchmark::microbenchmark(
fixed = str_detect(sentences, fixed("the")),
regex = str_detect(sentences, "the"),
times = 20)
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
a1 == a2
str_detect(a1, fixed(a2))
str_detect(a1, coll(a2)) # TRUE
i <- c("I", "İ", "i", "ı")
i
str_subset(i, coll("i", ignore_case = TRUE))
str_subset(
i,
coll("i", ignore_case = TRUE, locale = "tr") )
str_subset( i, coll("i", ignore_case = TRUE, locale = "tr") )
stringi::stri_locale_info()
# apropos() searches all objects available from the global environment.
apropos("replace")
# apropos() searches all objects available from the global environment.
apropos("count")
head(dir(pattern = "\\.Rmd$"))
# dir() lists all the files in a directory.
head(dir(pattern = "\\.Rmd$"))
x1 <- c("Dec", "Apr", "Jan", "Mar")
x2 <- c("Dec", "Apr", "Jam", "Mar")
sort(x1)
month_levels <- c(
"Jan", "Feb", "Mar", "Apr", "May", "Jun",
"Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
y1 <- factor(x1, levels = month_levels)
y1
sort(y1)
y2 <- factor(x2, levels = month_levels)
y2
y2 <- parse_factor(x2, levels = month_levels)
library(tidyverse)
library(nycflights13)
y2 <- parse_factor(x2, levels = month_levels)
factor(x1)
y1
factor(x1)
# Levels generated by default are in ascending alphabetical order
factor(x1)
f1 <- factor(x1, levels = unique(x1))
f1
f1 <- factor(x1, fct_inorder(x1))
f1
f2 <- x1 %>% factor() %>% fct_inorder()
f2
levels(f2)
gss_cat
gss_cat %>%
count(race)
ggplot(gss_cat,aes(race)) %>%
geom_bar()
ggplot(gss_cat,aes(race)) +
geom_bar()
ggplot(gss_cat,aes(race)) +
geom_bar() + scale_x_discrete()
ggplot(gss_cat,aes(race)) +
geom_bar() + scale_x_discrete(drop=F)
relig=gss_cat %>%
group_by(relig) %>% summarize(age=mean(age,na.rm=T),tvhours=mean(tv_hours,na.rm=T),n=n())
relig=gss_cat %>%
group_by(relig) %>% summarize(age=mean(age,na.rm=T),tvhours=mean(tvhours,na.rm=T),n=n())
relig
ggplot(relig)+
geom_point(aes(tvhours,relig))
# fct_reorder to reorder the relig on the basis of tvhours
fct_reorder(relig, tvhours)
# fct_reorder to reorder the relig on the basis of tvhours
relig %>% fct_reorder(relig, tvhours)
# fct_reorder to reorder the relig on the basis of tvhours
relig %>% fct_reorder(relig, tvhours)
religon=gss_cat %>%
group_by(relig) %>% summarize(age=mean(age,na.rm=T),tvhours=mean(tvhours,na.rm=T),n=n())
# fct_reorder to reorder the relig on the basis of tvhours
religon %>% fct_reorder(relig, tvhours)
# fct_reorder to reorder the relig on the basis of tvhours
religon %>% fct_reorder(relig, tvhours)
religon=gss_cat %>%
group_by(relig) %>% summarize(age=mean(age,na.rm=T),tvhours=mean(tvhours,na.rm=T),n=n())
relig
religon
# fct_reorder to reorder the relig on the basis of tvhours
religon %>% fct_reorder(relig, tvhours)
ggplot(religon, aes(tvhours, fct_reorder(relig, tvhours))) +
geom_point()
# fct_reorder to reorder the relig on the basis of tvhours
fct_reorder(religion$relig, religon$tvhours)
# fct_reorder to reorder the relig on the basis of tvhours
fct_reorder(religon$relig, religon$tvhours)
relig %>%
mutate(relig = fct_reorder(relig, tvhours)) %>%
ggplot(aes(tvhours, relig)) +
geom_point()
mutate(relig = fct_reorder(relig, tvhours)
religon %>%
religon %>%
mutate(relig = fct_reorder(relig, tvhours))
religon %>%
mutate(relig = fct_reorder(relig, tvhours))
religon %>%
mutate(reli = fct_reorder(relig, tvhours))
religon %>%
mutate(relig = fct_reorder(relig, tvhours))
religon=gss_cat %>%
group_by(relig) %>% summarize(age=mean(age,na.rm=T),tvhours=mean(tvhours,na.rm=T),n=n())
religon
ggplot(religon)+
geom_point(aes(tvhours,relig))
levels(religon$relig)
# fct_reorder to reorder the relig on the basis of tvhours
fct_reorder(religon$relig, religon$tvhours)
religion$relig
religon$relig
rincome <- gss_cat %>%
group_by(rincome) %>%
summarize(
age = mean(age, na.rm = TRUE),
tvhours = mean(tvhours, na.rm = TRUE),
n = n()
)
rincome
ggplot(
rincome,
aes(age, fct_reorder(rincome, age))
) + geom_point()
+ geom_point()
rincome,
aes(age, fct_reorder(rincome, age))
ggplot(
ggplot( rincome,aes(age, fct_reorder(rincome, age)))
rincome
ggplot( rincome,aes(age, fct_reorder(rincome, age)))
rincome <- gss_cat %>%
group_by(rincome) %>%
summarize(
age = mean(age, na.rm = TRUE),
tvhours = mean(tvhours, na.rm = TRUE),
n = n()
)
rincome
ggplot( rincome,aes(age, fct_reorder(rincome, age)))
ggplot(
rincome,
aes(age, fct_reorder(rincome, age))
) + geom_point()
ggplot( rincome, aes(age, fct_reorder(rincome, age))) +
geom_point()
by_age <- gss_cat %>% filter(!is.na(age)) %>%
group_by(age, marital) %>% count() %>%
mutate(prop = n / sum(n))
by_age
gss_cat %>% filter(!is.na(age)) %>%count(n())
gss_cat %>% filter(!is.na(age)) %>%count(age)
gss_cat %>% filter(!is.na(age)) %>%count(martial)
gss_cat %>% filter(!is.na(age)) %>%count(marital)
by_age
by_age <- gss_cat %>% filter(!is.na(age)) %>%
group_by(age, marital) %>% count() %>%
mutate(prop = n / sum(n),sum=sum(n))
by_age
by_age <- gss_cat %>% filter(!is.na(age)) %>%
group_by(age, marital) %>% count() %>%
mutate(prop = n / sum(n))
by_age
ggplot(by_age, aes(age, prop, color = marital)) +
geom_line(na.rm = TRUE)
ggplot(by_age, aes(age, n, color = marital)) +
geom_line(na.rm = TRUE)
ggplot( by_age,aes(age, prop, color = fct_reorder2(marital, age, prop))) +
geom_line() +labs(color = "marital")
ggplot( by_age,aes(age, n, color = fct_reorder2(marital, age, prop))) +
geom_line() +labs(color = "marital")
# fct_reorder2() reorders the factor by the y values associated with the largest x values.
ggplot( by_age,aes(age, n, color = fct_reorder2(marital, age, n))) +
geom_line() +labs(color = "marital")
# fct_infreq() to order levels in increasing frequency
gss_cat %>%
mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%
ggplot(aes(marital)) +
geom_bar()
# fct_infreq() to order levels in increasing frequency
gss_cat %>%
mutate(marital = marital %>% fct_infreq()) %>%
ggplot(aes(marital)) +
geom_bar()
gss_cat %>%
mutate(marital = marital %>% fct_infreq() %>% fct_rev())
gss_cat %>%
transmute(marital = marital %>% fct_infreq() %>% fct_rev())
gss_cat %>%
transmute(marital = marital %>% fct_infreq() %>% fct_rev()) %>% count()
gss_cat %>%
transmute(marital = marital %>% fct_infreq() %>% fct_rev()) %>% count(marital)
gss_cat %>%
transmute(marital = marital %>% fct_infreq() %>% fct_rev()) %>% count(marital) %>% marital
m=gss_cat %>%
transmute(marital = marital %>% fct_infreq() %>% fct_rev()) %>% count(marital)
print(m$marital)
gss_cat %>% count(partyid)
gss_cat %>%
mutate(partyid = fct_recode(partyid,
"Republican, strong" = "Strong republican",
"Republican, weak" = "Not str republican",
"Independent, near rep" = "Ind,near rep",
"Independent, near dem" = "Ind,near dem",
"Democrat, weak" = "Not str democrat",
"Democrat, strong" = "Strong democrat"
)) %>%
count(partyid)
# Modifying Values
gss_cat %>% count(partyid)
gss_cat %>% mutate(partyid = fct_recode(partyid,
"Republican, strong" = "Strong republican",
"Republican, weak" = "Not str republican",
"Independent, near rep" = "Ind,near rep",
"Independent, near dem" = "Ind,near dem",
"Democrat, weak" = "Not str democrat",
"Democrat, strong" = "Strong democrat" )) %>%
count(partyid)
# We can also combine groups or collapse using fct_recode
gss_cat %>% mutate(partyid = fct_recode(partyid,
"Republican, strong" = "Strong republican",
"Republican, weak" = "Not str republican",
"Independent, near rep" = "Ind,near rep",
"Independent, near dem" = "Ind,near dem",
"Democrat, weak" = "Not str democrat",
"Democrat, strong" = "Strong democrat",
"Other" = "No answer",
"Other" = "Don't know",
"Other" = "Other party")) %>%
count(partyid)
gss_cat %>%mutate(partyid = fct_collapse(partyid,
other = c("No answer", "Don't know", "Other party"),
rep = c("Strong republican", "Not str republican"),
ind = c("Ind,near rep", "Independent", "Ind,near dem"),
dem = c("Not str democrat", "Strong democrat"))) %>%
count(partyid)
# fct_lump combines or lump the all small groups together
gss_cat %>%
mutate(relig = fct_lump(relig)) %>%
count(relig)
count(relig)
# give n value to decide the total no. of groups after lump
gss_cat %>%
mutate(relig = fct_lump(relig, n = 10)) %>%
count(relig, sort = TRUE) %>%
print(n = Inf)
